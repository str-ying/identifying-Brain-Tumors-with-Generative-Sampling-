{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ZJyIQRjgcxE7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GzoCoWu1c2Z",
        "outputId": "3c6c1235-39c7-4c64-d793-ae13979852a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape, MaxPool2D, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow._api.v2.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "WIP4PK9x1rh9",
        "outputId": "eab37d2c-7827-4da8-f9b3-e907fb2b7eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-45fbddaf1946>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Datasets\n",
        "img_dir='brain_tumor/'\n",
        "no_images=os.listdir(img_dir + 'no/')\n",
        "yes_images=os.listdir(img_dir + 'yes/')\n",
        "dataset=[]\n",
        "lab=[]\n",
        "\n",
        "#No tumour images\n",
        "for image_name in no_images:\n",
        "    image=cv2.imread(img_dir + 'no/' +image_name)\n",
        "    image=Image.fromarray(image,'RGB')\n",
        "    image=image.resize((112,112))\n",
        "    dataset.append(np.array(image))\n",
        "    lab.append(0)\n",
        "\n",
        "#Tumour images\n",
        "for image_name in yes_images:\n",
        "    image=cv2.imread(img_dir + 'yes/' +image_name)\n",
        "    image=Image.fromarray(image,'RGB')\n",
        "    image=image.resize((112,112))\n",
        "    dataset.append(np.array(image))\n",
        "    lab.append(1)\n",
        "\n",
        "data=np.asarray(dataset)\n",
        "l=np.asarray(lab)\n",
        "print(data.shape, l.shape)\n",
        "print('Total Number of Image: ',len(l))\n",
        "\n"
      ],
      "metadata": {
        "id": "N_f-mBv41srY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(data,l, test_size=0.3, shuffle=True, random_state=0, stratify=l)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# Reshape \n",
        "\n",
        "img_width  = x_train.shape[1]\n",
        "img_height = x_train.shape[2]\n",
        "num_channels = x_train.shape[3]\n",
        "# x_train = x_train.reshape(x_train.shape[0], img_height, img_width, num_channels)\n",
        "# x_test = x_test.reshape(x_test.shape[0], img_height, img_width, num_channels)\n",
        "input_shape = (img_height, img_width, num_channels)"
      ],
      "metadata": {
        "id": "SONFk6OR1xI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search"
      ],
      "metadata": {
        "id": "tsGG1RKXc2CE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier():\n",
        "  model = Sequential()\n",
        "  #\n",
        "  model.add(Conv2D(32, (5,5), activation ='relu', input_shape = (112,112,3)))\n",
        "  model.add(MaxPool2D(pool_size=(2,2)))\n",
        "  #\n",
        "  model.add(Conv2D(64, (3,3),activation ='relu'))\n",
        "  model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), ))\n",
        "\n",
        "  # fully connected\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation = \"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(10, activation = \"softmax\"))\n",
        "  model.compile(optimizer = 'adam' , loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "sbS3mqf0Xsxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience = 5)"
      ],
      "metadata": {
        "id": "ONqLOs6jFBD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV \n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "model = KerasClassifier(build_fn = classifier, epochs=15)\n",
        "#What hyperparameter we want to play with\n",
        "parameters = {'batch_size': [5, 10, 15, 20]}\n",
        "grid_search = GridSearchCV(estimator = model,\n",
        "                           param_grid = parameters,\n",
        "                           cv = 3)\n",
        "grid_search = grid_search.fit(x_train, y_train, validation_split = 0.2, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "Nes8PuGhXQf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best: %f using %s\" % (grid_search.best_score_, grid_search.best_params_))\n",
        "means = grid_search.cv_results_['mean_test_score']\n",
        "stds = grid_search.cv_results_['std_test_score']\n",
        "params = grid_search.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "kS3yb-s3YGNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "oYg9T-X9igcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#\n",
        "model.add(Conv2D(32, (5,5), activation ='relu', input_shape = (112,112,3)))\n",
        "#model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3,3),activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), ))\n",
        "\n",
        "# fully connected\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation = \"softmax\"))\n",
        "model.compile(optimizer = 'adam' , loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "rlHchmdSikNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience = 4)"
      ],
      "metadata": {
        "id": "Zo8Jq3l8jZ5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam' , loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history= model.fit(x_train, y_train, epochs = 20, batch_size = 15, validation_split = 0.2, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "id": "REnAhc-U_Zv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NyhOpWPu_-Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.title('model acc')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3ZLCKIUzmxfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "id": "qLN1PtxEI_f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "FwQph1SGJBy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(np.round(y_pred),axis=1)\n"
      ],
      "metadata": {
        "id": "qCsI6AwwRbKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "-BIRnbISRhBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = np.where(y_pred==y_test)[0]\n",
        "print( \"Found %d correct labels\" % len(correct))\n",
        "for i, correct in enumerate(correct[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(x_test[correct], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(y_pred[correct], y_test[correct]))\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "Vp-d_g6WRrNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect = np.where(y_pred!=y_test)[0]\n",
        "print( \"Found %d incorrect labels\" % len(incorrect))\n",
        "for i, incorrect in enumerate(incorrect[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(x_test[incorrect], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(y_pred[incorrect], y_test[incorrect]))\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "SYxSVmmPSHa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generated Pre Processing"
      ],
      "metadata": {
        "id": "BfNZs5HYmrTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Datasets\n",
        "img_dir='brain_tumor_extra/brain_tumor/'\n",
        "no_images=os.listdir(img_dir + 'no/')\n",
        "yes_images=os.listdir(img_dir + 'yes/')\n",
        "dataset=[]\n",
        "lab=[]\n",
        "\n",
        "#No tumour images\n",
        "for image_name in no_images:\n",
        "    image=cv2.imread(img_dir + 'no/' +image_name)\n",
        "    image=Image.fromarray(image,'RGB')\n",
        "    image=image.resize((112,112))\n",
        "    dataset.append(np.array(image))\n",
        "    lab.append(0)\n",
        "\n",
        "#Tumour images\n",
        "for image_name in yes_images:\n",
        "    image=cv2.imread(img_dir + 'yes/' +image_name)\n",
        "    image=Image.fromarray(image,'RGB')\n",
        "    image=image.resize((112,112))\n",
        "    dataset.append(np.array(image))\n",
        "    lab.append(1)\n",
        "\n",
        "data=np.asarray(dataset)\n",
        "l=np.asarray(lab)\n",
        "print(data.shape, l.shape)\n",
        "print('Total Number of Image: ',len(l))\n",
        "\n"
      ],
      "metadata": {
        "id": "vZwOAA_Ami7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(data,l, test_size=0.3, shuffle=True, random_state=0, stratify=l)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# Reshape \n",
        "\n",
        "img_width  = x_train.shape[1]\n",
        "img_height = x_train.shape[2]\n",
        "num_channels = x_train.shape[3]\n",
        "# x_train = x_train.reshape(x_train.shape[0], img_height, img_width, num_channels)\n",
        "# x_test = x_test.reshape(x_test.shape[0], img_height, img_width, num_channels)\n",
        "input_shape = (img_height, img_width, num_channels)"
      ],
      "metadata": {
        "id": "h47pg_J5nEM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generated Training"
      ],
      "metadata": {
        "id": "w3rPH7BWnJg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#\n",
        "model.add(Conv2D(32, (5,5), activation ='relu', input_shape = (112,112,3)))\n",
        "#model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3,3),activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2), ))\n",
        "\n",
        "# fully connected\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation = \"softmax\"))\n",
        "model.compile(optimizer = 'adam' , loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "hzpKrijUaCI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience = 4)"
      ],
      "metadata": {
        "id": "RpOYiTLcaCI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam' , loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "history= model.fit(x_train, y_train, epochs = 20, batch_size = 15, validation_split = 0.2, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "id": "rkB8nQTkaCI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0G5ese3haCI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.title('model acc')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "myrF4NhoaCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "id": "Gx-gJVTFaCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "5EX84brLaCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax(np.round(y_pred),axis=1)\n"
      ],
      "metadata": {
        "id": "KvKwCFZ-aCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "lwwWgngxaCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = np.where(y_pred==y_test)[0]\n",
        "print( \"Found %d correct labels\" % len(correct))\n",
        "for i, correct in enumerate(correct[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(x_test[correct], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(y_pred[correct], y_test[correct]))\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "q-g_Z4JraCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect = np.where(y_pred!=y_test)[0]\n",
        "print( \"Found %d incorrect labels\" % len(incorrect))\n",
        "for i, incorrect in enumerate(incorrect[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(x_test[incorrect], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(y_pred[incorrect], y_test[incorrect]))\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "P5dJoE3WaCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "-oTBX7GrQllY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X1SVD0u7QmZP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}